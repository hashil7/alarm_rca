{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "\n",
    "def build_network_graph(topology_df):\n",
    "    \"\"\"Build a graph from topology_data_logical table\"\"\"\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes and edges with attributes\n",
    "    for _, row in topology_df.iterrows():\n",
    "        aend = row['aendname'].upper()\n",
    "        bend = row['bendname'].upper()\n",
    "        \n",
    "        # Add node attributes\n",
    "        G.add_node(aend, ip=row['aendip'], \n",
    "                   physicalringname=row['physicalringname'], \n",
    "                   lrname=row['lrname'],\n",
    "                   block_name=row['block_name'])\n",
    "        \n",
    "        G.add_node(bend, ip=row['bendip'], \n",
    "                   physicalringname=row['physicalringname'], \n",
    "                   lrname=row['lrname'],\n",
    "                   block_name=row['block_name'])\n",
    "        \n",
    "        # Add edge with attributes\n",
    "        G.add_edge(aend, bend, \n",
    "                  physicalringname=row['physicalringname'], \n",
    "                  lrname=row['lrname'],\n",
    "                  aendifIndex=row['aendifIndex'],\n",
    "                  bendifIndex=row['bendifIndex'])\n",
    "    \n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_node_failure(G, node_to_fail):\n",
    "    \"\"\"\n",
    "    Simulate a node failure and identify isolated nodes\n",
    "    \n",
    "    Returns:\n",
    "        - isolated_nodes: list of nodes that become isolated\n",
    "    \"\"\"\n",
    "    # Get the node's ring information\n",
    "    if node_to_fail not in G.nodes():\n",
    "        return []\n",
    "    \n",
    "    node_pr = G.nodes[node_to_fail]['physicalringname']\n",
    "    node_lr = G.nodes[node_to_fail]['lrname']\n",
    "    block_name = G.nodes[node_to_fail]['block_name']\n",
    "    \n",
    "    # Get all connected nodes in the same ring before failure\n",
    "    before_graph = G.copy()\n",
    "    block_component = set(nx.node_connected_component(before_graph, block_name))\n",
    "    connected_before = {n for n in block_component \n",
    "                        if n in before_graph.nodes() and \n",
    "                        before_graph.nodes[n].get('physicalringname') == node_pr and \n",
    "                        before_graph.nodes[n].get('lrname') == node_lr}\n",
    "    \n",
    "    # Remove the failed node\n",
    "    after_graph = G.copy()\n",
    "    after_graph.remove_node(node_to_fail)\n",
    "    \n",
    "    # Get connected nodes after failure\n",
    "    if block_name in after_graph.nodes():\n",
    "        block_component_after = set(nx.node_connected_component(after_graph, block_name))\n",
    "        connected_after = {n for n in block_component_after \n",
    "                          if n in after_graph.nodes() and \n",
    "                          after_graph.nodes[n].get('physicalringname') == node_pr and \n",
    "                          after_graph.nodes[n].get('lrname') == node_lr}\n",
    "    else:\n",
    "        connected_after = set()\n",
    "    \n",
    "    # Find isolated nodes (nodes connected before but not after)\n",
    "    isolated_nodes = connected_before - connected_after - {node_to_fail}\n",
    "    \n",
    "    return list(isolated_nodes)\n",
    "\n",
    "def simulate_edge_failure(G, edge_to_fail):\n",
    "    \"\"\"\n",
    "    Simulate an edge failure and identify isolated nodes\n",
    "    \n",
    "    Returns:\n",
    "        - isolated_nodes: list of nodes that become isolated\n",
    "    \"\"\"\n",
    "    u, v = edge_to_fail\n",
    "    if not G.has_edge(u, v):\n",
    "        return []\n",
    "    \n",
    "    # Get edge information\n",
    "    edge_pr = G.edges[u, v]['physicalringname']\n",
    "    edge_lr = G.edges[u, v]['lrname']\n",
    "    block_name = G.nodes[u]['block_name']  # Assuming same block for connected nodes\n",
    "    \n",
    "    # Get connected nodes before failure\n",
    "    before_graph = G.copy()\n",
    "    block_component = set(nx.node_connected_component(before_graph, block_name))\n",
    "    connected_before = {n for n in block_component \n",
    "                        if n in before_graph.nodes() and \n",
    "                        before_graph.nodes[n].get('physicalringname') == edge_pr and \n",
    "                        before_graph.nodes[n].get('lrname') == edge_lr}\n",
    "    \n",
    "    # Remove the edge\n",
    "    after_graph = G.copy()\n",
    "    after_graph.remove_edge(u, v)\n",
    "    \n",
    "    # Get connected nodes after failure\n",
    "    block_component_after = set(nx.node_connected_component(after_graph, block_name))\n",
    "    connected_after = {n for n in block_component_after \n",
    "                       if n in after_graph.nodes() and \n",
    "                       after_graph.nodes[n].get('physicalringname') == edge_pr and \n",
    "                       after_graph.nodes[n].get('lrname') == edge_lr}\n",
    "    \n",
    "    # Find isolated nodes\n",
    "    isolated_nodes = connected_before - connected_after\n",
    "    \n",
    "    return list(isolated_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gnn_dataset(topology_df, num_simulations=100):\n",
    "    \"\"\"\n",
    "    Create a dataset for training a GNN to predict isolated nodes\n",
    "    \n",
    "    Returns:\n",
    "        - List of PyTorch Geometric Data objects\n",
    "    \"\"\"\n",
    "    # Build the graph\n",
    "    G = build_network_graph(topology_df)\n",
    "    \n",
    "    # Node mapping (for creating numerical indices)\n",
    "    node_list = list(G.nodes())\n",
    "    node_to_idx = {node: i for i, node in enumerate(node_list)}\n",
    "    \n",
    "    # Create node features\n",
    "    node_features = []\n",
    "    for node in node_list:\n",
    "        # Feature 1: One-hot encoded physical ring\n",
    "        pr = G.nodes[node]['physicalringname']\n",
    "        pr_hash = hash(pr) % 10  # Simple encoding\n",
    "        \n",
    "        # Feature 2: One-hot encoded logical ring\n",
    "        lr = G.nodes[node]['lrname']\n",
    "        lr_hash = hash(lr) % 10  # Simple encoding\n",
    "        \n",
    "        # Feature 3: Is it a block node?\n",
    "        is_block = 1.0 if node == G.nodes[node]['block_name'] else 0.0\n",
    "        \n",
    "        # Feature 4-5: Degree centrality and clustering coefficient\n",
    "        degree = G.degree(node) / len(G)\n",
    "        clustering = nx.clustering(G, node)\n",
    "        \n",
    "        node_features.append([pr_hash/10.0, lr_hash/10.0, is_block, degree, clustering])\n",
    "    \n",
    "    node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "    \n",
    "    # Create edge index for PyG\n",
    "    edges = []\n",
    "    for u, v in G.edges():\n",
    "        edges.append([node_to_idx[u], node_to_idx[v]])\n",
    "        edges.append([node_to_idx[v], node_to_idx[u]])  # Add reverse edge for undirected graph\n",
    "    \n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    # Create dataset entries\n",
    "    data_list = []\n",
    "    \n",
    "    # Simulate node failures\n",
    "    for _ in range(num_simulations // 2):  # Half node failures, half edge failures\n",
    "        # Randomly select a node to fail\n",
    "        node_to_fail = np.random.choice(node_list)\n",
    "        \n",
    "        # Find isolated nodes\n",
    "        isolated_nodes = simulate_node_failure(G, node_to_fail)\n",
    "        \n",
    "        # Create target tensor (1 for isolated nodes, 0 for others)\n",
    "        y = torch.zeros(len(node_list), dtype=torch.float)\n",
    "        for node in isolated_nodes:\n",
    "            y[node_to_idx[node]] = 1.0\n",
    "        \n",
    "        # Create node failure mask\n",
    "        node_mask = torch.zeros(len(node_list), dtype=torch.bool)\n",
    "        node_mask[node_to_idx[node_to_fail]] = True\n",
    "        \n",
    "        # Create PyG Data object\n",
    "        data = Data(\n",
    "            x=node_features,\n",
    "            edge_index=edge_index,\n",
    "            y=y,\n",
    "            failed_node_mask=node_mask,\n",
    "            failed_edge_mask=None\n",
    "        )\n",
    "        \n",
    "        data_list.append(data)\n",
    "    \n",
    "    # Simulate edge failures\n",
    "    edge_list = list(G.edges())\n",
    "    for _ in range(num_simulations // 2):\n",
    "        # Randomly select an edge to fail\n",
    "        edge_to_fail = edge_list[np.random.randint(0, len(edge_list))]\n",
    "        \n",
    "        # Find isolated nodes\n",
    "        isolated_nodes = simulate_edge_failure(G, edge_to_fail)\n",
    "        \n",
    "        # Create target tensor\n",
    "        y = torch.zeros(len(node_list), dtype=torch.float)\n",
    "        for node in isolated_nodes:\n",
    "            y[node_to_idx[node]] = 1.0\n",
    "        \n",
    "        # Create edge failure mask\n",
    "        edge_mask = torch.zeros(edge_index.size(1), dtype=torch.bool)\n",
    "        u_idx, v_idx = node_to_idx[edge_to_fail[0]], node_to_idx[edge_to_fail[1]]\n",
    "        \n",
    "        for i in range(edge_index.size(1)):\n",
    "            e_u, e_v = edge_index[0, i].item(), edge_index[1, i].item()\n",
    "            if (e_u == u_idx and e_v == v_idx) or (e_u == v_idx and e_v == u_idx):\n",
    "                edge_mask[i] = True\n",
    "        \n",
    "        # Create PyG Data object\n",
    "        data = Data(\n",
    "            x=node_features,\n",
    "            edge_index=edge_index,\n",
    "            y=y,\n",
    "            failed_node_mask=None,\n",
    "            failed_edge_mask=edge_mask\n",
    "        )\n",
    "        \n",
    "        data_list.append(data)\n",
    "    \n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "def load_topology_data(config):\n",
    "    \"\"\"Load topology data from MySQL database\"\"\"\n",
    "    connection = mysql.connector.connect(**config)\n",
    "    cursor = connection.cursor(dictionary=True)\n",
    "    \n",
    "    query = \"\"\"\n",
    "        SELECT \n",
    "           aendname, \n",
    "           bendname, \n",
    "           aendip, \n",
    "           bendip, \n",
    "           aendifIndex,\n",
    "           bendifIndex,\n",
    "           block_name, \n",
    "           physicalringname, \n",
    "           lrname \n",
    "        FROM topology_data_logical\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    connection.close()\n",
    "    \n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Pakhanjur'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m topology_df = load_topology_data(db_config)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Create dataset for GNN training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m data_list = \u001b[43mcreate_gnn_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopology_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_simulations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCreated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data_list)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m data entries\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mcreate_gnn_dataset\u001b[39m\u001b[34m(topology_df, num_simulations)\u001b[39m\n\u001b[32m     51\u001b[39m node_to_fail = np.random.choice(node_list)\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Find isolated nodes\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m isolated_nodes = \u001b[43msimulate_node_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_to_fail\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Create target tensor (1 for isolated nodes, 0 for others)\u001b[39;00m\n\u001b[32m     57\u001b[39m y = torch.zeros(\u001b[38;5;28mlen\u001b[39m(node_list), dtype=torch.float)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36msimulate_node_failure\u001b[39m\u001b[34m(G, node_to_fail)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Get all connected nodes in the same ring before failure\u001b[39;00m\n\u001b[32m     17\u001b[39m before_graph = G.copy()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m block_component = \u001b[38;5;28mset\u001b[39m(\u001b[43mnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnode_connected_component\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbefore_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_name\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     19\u001b[39m connected_before = {n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m block_component \n\u001b[32m     20\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m before_graph.nodes() \u001b[38;5;129;01mand\u001b[39;00m \n\u001b[32m     21\u001b[39m                     before_graph.nodes[n].get(\u001b[33m'\u001b[39m\u001b[33mphysicalringname\u001b[39m\u001b[33m'\u001b[39m) == node_pr \u001b[38;5;129;01mand\u001b[39;00m \n\u001b[32m     22\u001b[39m                     before_graph.nodes[n].get(\u001b[33m'\u001b[39m\u001b[33mlrname\u001b[39m\u001b[33m'\u001b[39m) == node_lr}\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Remove the failed node\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/networkx/utils/decorators.py:788\u001b[39m, in \u001b[36margmap.__call__.<locals>.func\u001b[39m\u001b[34m(_argmap__wrapper, *args, **kwargs)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunc\u001b[39m(*args, __wrapper=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43margmap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_lazy_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__wrapper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<class 'networkx.utils.decorators.argmap'> compilation 13:4\u001b[39m, in \u001b[36margmap_node_connected_component_9\u001b[39m\u001b[34m(G, n, backend, **backend_kwargs)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgzip\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitertools\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/networkx/utils/backends.py:967\u001b[39m, in \u001b[36m_dispatchable.__call__\u001b[39m\u001b[34m(self, backend, *args, **kwargs)\u001b[39m\n\u001b[32m    965\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m backend != \u001b[33m\"\u001b[39m\u001b[33mnetworkx\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    966\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m backend is not installed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m967\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43morig_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`.\u001b[39;00m\n\u001b[32m    970\u001b[39m \u001b[38;5;66;03m# This is purely for aesthetics and to make it easier to search for this\u001b[39;00m\n\u001b[32m    971\u001b[39m \u001b[38;5;66;03m# variable since \"backend\" is used in many comments and log/error messages.\u001b[39;00m\n\u001b[32m    972\u001b[39m backend_name = backend\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/networkx/algorithms/components/connected.py:198\u001b[39m, in \u001b[36mnode_connected_component\u001b[39m\u001b[34m(G, n)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;129m@not_implemented_for\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mdirected\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    161\u001b[39m \u001b[38;5;129m@nx\u001b[39m._dispatchable\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnode_connected_component\u001b[39m(G, n):\n\u001b[32m    163\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Returns the set of nodes in the component of graph containing node n.\u001b[39;00m\n\u001b[32m    164\u001b[39m \n\u001b[32m    165\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    196\u001b[39m \n\u001b[32m    197\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_plain_bfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/networkx/algorithms/components/connected.py:210\u001b[39m, in \u001b[36m_plain_bfs\u001b[39m\u001b[34m(G, n, source)\u001b[39m\n\u001b[32m    208\u001b[39m nextlevel = []\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m thislevel:\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[43madj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[32m    211\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m seen:\n\u001b[32m    212\u001b[39m             seen.add(w)\n",
      "\u001b[31mKeyError\u001b[39m: 'Pakhanjur'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Database configuration\n",
    "db_config = {\n",
    "    \"host\": \"192.168.30.15\",\n",
    "    \"user\": \"nms\",\n",
    "    \"password\": \"Nms@1234\",\n",
    "    \"database\": \"cnmsip\"\n",
    "}\n",
    "\n",
    "# Load topology data\n",
    "topology_df = load_topology_data(db_config)\n",
    "\n",
    "# Create dataset for GNN training\n",
    "data_list = create_gnn_dataset(topology_df, num_simulations=200)\n",
    "print(f\"Created {len(data_list)} data entries\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
